{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc21f04-b96c-44fa-be2b-220e2c071957",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc6ed331-159e-481a-9e82-85c6b32faa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step \n"
     ]
    }
   ],
   "source": [
    "(train_images,train_labels),(test_images,test_labels)=mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bba6a3-6503-4b7e-b87b-491d5b0866ea",
   "metadata": {},
   "source": [
    "train_images 和 train_labels 组成了训练集（training set），模型将从这些数据中进行学习。然后在测试集（test set，即 test_images 和 test_labels）上对模型进行测试。          \n",
    "图像被编码为 Numpy 数组，而标签是数字数组，取值范围为 0~9。图像和标签一一对应。\n",
    "我们来看一下训练数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "810e91e6-e0ca-4fac-81d2-6a080efb4a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6388caf9-3f0e-4d19-b49d-a88da4a64b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62fe917f-7d6a-486b-986e-d3ee2d87e89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29474f-b9c9-4268-939b-f132d63fbedd",
   "metadata": {},
   "source": [
    "### 下面是测试数据: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7051788-ce43-431f-8bd9-b74338b2af9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03adba6d-48c2-4c27-98ae-c561d7e8106a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bbff10e-b462-4b4e-ad80-0637daa3c5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa57254-4ed1-4529-88ed-8bd02a647dcc",
   "metadata": {},
   "source": [
    "接下来的工作流程如下：首先，将训练数据（train_images 和 train_labels）输入神\n",
    "经网络；其次，网络学习将图像和标签关联在一起；最后，网络对 test_images 生成预测，\n",
    "而我们将验证这些预测与 test_labels 中的标签是否匹配。\n",
    "下面我们来构建网络。再说一遍，你现在不需要理解这个例子的全部内容。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83ea3fd8-f151-411b-8fbc-3242c523d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81f083af-13e3-40d6-bd0a-5474441b48df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0munits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'glorot_uniform'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'zeros'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mactivity_regularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mkernel_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbias_constraint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlora_rank\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m     \n",
       "Just your regular densely-connected NN layer.\n",
       "\n",
       "`Dense` implements the operation:\n",
       "`output = activation(dot(input, kernel) + bias)`\n",
       "where `activation` is the element-wise activation function\n",
       "passed as the `activation` argument, `kernel` is a weights matrix\n",
       "created by the layer, and `bias` is a bias vector created by the layer\n",
       "(only applicable if `use_bias` is `True`).\n",
       "\n",
       "Note: If the input to the layer has a rank greater than 2, `Dense`\n",
       "computes the dot product between the `inputs` and the `kernel` along the\n",
       "last axis of the `inputs` and axis 0 of the `kernel` (using `tf.tensordot`).\n",
       "For example, if input has dimensions `(batch_size, d0, d1)`, then we create\n",
       "a `kernel` with shape `(d1, units)`, and the `kernel` operates along axis 2\n",
       "of the `input`, on every sub-tensor of shape `(1, 1, d1)` (there are\n",
       "`batch_size * d0` such sub-tensors). The output in this case will have\n",
       "shape `(batch_size, d0, units)`.\n",
       "\n",
       "Args:\n",
       "    units: Positive integer, dimensionality of the output space.\n",
       "    activation: Activation function to use.\n",
       "        If you don't specify anything, no activation is applied\n",
       "        (ie. \"linear\" activation: `a(x) = x`).\n",
       "    use_bias: Boolean, whether the layer uses a bias vector.\n",
       "    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
       "    bias_initializer: Initializer for the bias vector.\n",
       "    kernel_regularizer: Regularizer function applied to\n",
       "        the `kernel` weights matrix.\n",
       "    bias_regularizer: Regularizer function applied to the bias vector.\n",
       "    activity_regularizer: Regularizer function applied to\n",
       "        the output of the layer (its \"activation\").\n",
       "    kernel_constraint: Constraint function applied to\n",
       "        the `kernel` weights matrix.\n",
       "    bias_constraint: Constraint function applied to the bias vector.\n",
       "    lora_rank: Optional integer. If set, the layer's forward pass\n",
       "        will implement LoRA (Low-Rank Adaptation)\n",
       "        with the provided rank. LoRA sets the layer's kernel\n",
       "        to non-trainable and replaces it with a delta over the\n",
       "        original kernel, obtained via multiplying two lower-rank\n",
       "        trainable matrices. This can be useful to reduce the\n",
       "        computation cost of fine-tuning large dense layers.\n",
       "        You can also enable LoRA on an existing\n",
       "        `Dense` layer by calling `layer.enable_lora(rank)`.\n",
       "\n",
       "Input shape:\n",
       "    N-D tensor with shape: `(batch_size, ..., input_dim)`.\n",
       "    The most common situation would be\n",
       "    a 2D input with shape `(batch_size, input_dim)`.\n",
       "\n",
       "Output shape:\n",
       "    N-D tensor with shape: `(batch_size, ..., units)`.\n",
       "    For instance, for a 2D input with shape `(batch_size, input_dim)`,\n",
       "    the output would have shape `(batch_size, units)`.\n",
       "\u001b[1;31mFile:\u001b[0m           d:\\envs\\dl\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers.Dense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5219f-6189-4058-85d4-3fb0e4401f72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
